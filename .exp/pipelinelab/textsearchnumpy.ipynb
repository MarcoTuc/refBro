{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from itertools import combinations\n",
    "\n",
    "import asyncio\n",
    "import aiohttp\n",
    "\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_OPENALEX = \"https://api.openalex.org\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"dna kinetics\",\n",
    "    \"graph theory\",\n",
    "    \"dynamical systems\",\n",
    "    \"monte carlo simulations\",\n",
    "    \"origins of life\",\n",
    "    \"stochastic processes\",\n",
    "    \"polymer physics\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Async version\n",
    "async def fetch_papers_async(query: str, n_results=1000):\n",
    "    query = \"%20\".join(query.split(\" \"))\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        per_page = 200\n",
    "        pages = (n_results // per_page) + 1\n",
    "        for page in range(1, pages + 1):\n",
    "            url = f\"{BASE_OPENALEX}/works?search={query}&per-page={per_page}&page={page}\"\n",
    "            tasks.append(session.get(url))\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "        results = []\n",
    "        for response in responses:\n",
    "            data = await response.json()\n",
    "            results.extend(data['results'])\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def search_papers(query: str, n_results=400) -> pd.DataFrame:\n",
    "    \"\"\" Retrieve n_results out of a query to openalex \"\"\"\n",
    "    per_page = min(200, n_results)\n",
    "    query = \"%20\".join(query.split(\" \"))\n",
    "    url = f\"{BASE_OPENALEX}/works?search={query}\"\n",
    "    params = {\n",
    "        'per-page': per_page,\n",
    "    }\n",
    "    dfs = []\n",
    "    for page in range(1, (n_results // per_page)+1):\n",
    "        params['page'] = page\n",
    "        response = requests.get(url, params=params).json()\n",
    "        df = pd.json_normalize(response[\"results\"])\n",
    "        df = df.drop(columns=[col for col in df.columns if 'abstract' in col.lower()])\n",
    "        dfs.append(df)            \n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "async def multi_search(queries: List[str], n_results=400) -> pd.DataFrame:\n",
    "    \"\"\" Returns a dataframe with all retrieved papers for all queries \"\"\"\n",
    "    results = {}\n",
    "    for query in queries: \n",
    "        results[query] = await fetch_papers_async(query, n_results=n_results)\n",
    "    return pd.concat(list(results.values()), ignore_index=True)\n",
    "\n",
    "def get_topics_set(results: pd.DataFrame):\n",
    "    topics = results[\"topics\"]\n",
    "    topic_ids = []\n",
    "    for topic in topics:\n",
    "        for t in topic: \n",
    "            topic_ids.append(t[\"id\"])\n",
    "    return set(topic_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = await multi_search(queries, n_results=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = get_topics_set(results)\n",
    "t_idx = {i:t for i,t in enumerate(topics)}\n",
    "idx_t = {t:i for i,t in t_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a matrix to index through topics \n",
    "mutualmatrix = np.zeros([len(topics), len(topics)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, res in results.iterrows():\n",
    "    # get p(x)\n",
    "    for t in res[\"topics\"]:\n",
    "        id = idx_t[t[\"id\"]]\n",
    "        mutualmatrix[id, id] = mutualmatrix[id, id] + 1\n",
    "    # get p(x, y)\n",
    "    for ti, tj in combinations(res[\"topics\"], r=2):\n",
    "        idi, idj = idx_t[ti[\"id\"]], idx_t[tj[\"id\"]]\n",
    "        mutualmatrix[idi, idj] = mutualmatrix[idi, idj] + 1\n",
    "        mutualmatrix[idj, idi] = mutualmatrix[idj, idi] + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-zero elements in mutual matrix: 18001\n",
      "Total sum of values in mutual matrix: 63228.0\n"
     ]
    }
   ],
   "source": [
    "# Count non-zero elements and total sum in the mutual matrix\n",
    "nonzero_count = (mutualmatrix != 0).sum().sum()\n",
    "total_sum = mutualmatrix.sum().sum()\n",
    "print(f\"Number of non-zero elements in mutual matrix: {nonzero_count}\")\n",
    "print(f\"Total sum of values in mutual matrix: {total_sum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(mutualmatrix)\n",
    "probmatrix = mutualmatrix/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pmimatrix = np.zeros_like(probmatrix)\n",
    "for i,j in combinations(range(probmatrix.shape[0]), r=2):\n",
    "    if probmatrix[i,j] > 0:\n",
    "        pmimatrix[i,j] = np.log2(probmatrix[i,j]/(probmatrix[i,i]*probmatrix[j,j]))/(-np.log2(probmatrix[i,j]))\n",
    "        pmimatrix[j,i] = pmimatrix[i,j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1437702/3381889387.py:6: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise an error in a future version of pandas. Value '-0.28445786476728635' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n",
      "  results.loc[i, \"score\"] += pmimatrix[idx_t[ti[\"id\"]], idx_t[tj[\"id\"]]]\n"
     ]
    }
   ],
   "source": [
    "results[\"score\"] = 0\n",
    "for i, work in results.iterrows():\n",
    "    topics = work[\"topics\"]\n",
    "    for ti, tj in combinations(topics, r=2):\n",
    "        # Fix: use ti and tj for the two different indices\n",
    "        results.loc[i, \"score\"] += pmimatrix[idx_t[ti[\"id\"]], idx_t[tj[\"id\"]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = results.sort_values(by=\"score\", ascending=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
