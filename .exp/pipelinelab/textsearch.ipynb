{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from itertools import combinations\n",
    "\n",
    "import asyncio\n",
    "import aiohttp\n",
    "\n",
    "import json\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_OPENALEX = \"https://api.openalex.org\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"dna kinetics\",\n",
    "    \"graph theory\",\n",
    "    \"dynamical systems\",\n",
    "    \"monte carlo simulations\",\n",
    "    \"origins of life\",\n",
    "    \"stochastic processes\",\n",
    "    \"polymer physics\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Async version\n",
    "async def fetch_papers_async(query: str, n_results=1000):\n",
    "    query = \"%20\".join(query.split(\" \"))\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        per_page = 200\n",
    "        pages = (n_results // per_page) + 1\n",
    "        for page in range(1, pages + 1):\n",
    "            url = f\"{BASE_OPENALEX}/works?search={query}&per-page={per_page}&page={page}\"\n",
    "            tasks.append(session.get(url))\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "        results = []\n",
    "        for response in responses:\n",
    "            data = await response.json()\n",
    "            results.extend(data['results'])\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def search_papers(query: str, n_results=400) -> pd.DataFrame:\n",
    "    \"\"\" Retrieve n_results out of a query to openalex \"\"\"\n",
    "    per_page = min(200, n_results)\n",
    "    query = \"%20\".join(query.split(\" \"))\n",
    "    url = f\"{BASE_OPENALEX}/works?search={query}\"\n",
    "    params = {\n",
    "        'per-page': per_page,\n",
    "    }\n",
    "    dfs = []\n",
    "    for page in range(1, (n_results // per_page)+1):\n",
    "        params['page'] = page\n",
    "        response = requests.get(url, params=params).json()\n",
    "        df = pd.json_normalize(response[\"results\"])\n",
    "        df = df.drop(columns=[col for col in df.columns if 'abstract' in col.lower()])\n",
    "        dfs.append(df)            \n",
    "    return pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "async def multi_search(queries: List[str], n_results=400) -> pd.DataFrame:\n",
    "    \"\"\" Returns a dataframe with all retrieved papers for all queries \"\"\"\n",
    "    results = {}\n",
    "    for query in queries: \n",
    "        results[query] = await fetch_papers_async(query, n_results=n_results)\n",
    "    return pd.concat(list(results.values()), ignore_index=True)\n",
    "\n",
    "def get_topics_set(results: pd.DataFrame):\n",
    "    topics = results[\"topics\"]\n",
    "    topic_ids = []\n",
    "    for topic in topics:\n",
    "        for t in topic: \n",
    "            topic_ids.append(t[\"id\"])\n",
    "    return set(topic_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = await multi_search(queries, n_results=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "topics = get_topics_set(results)\n",
    "t_idx = {i:t for i,t in enumerate(topics)}\n",
    "idx_t = {t:i for i,t in t_idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a matrix to index through topics \n",
    "mutualmatrix = pd.DataFrame(0, index=list(topics), columns=list(topics))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, res in results.iterrows():\n",
    "    # get p(x)\n",
    "    for t in res[\"topics\"]:\n",
    "        id = t[\"id\"]\n",
    "        mutualmatrix.loc[id, id] = mutualmatrix.loc[id, id] + 1\n",
    "    # get p(x, y)\n",
    "    for ti, tj in combinations(res[\"topics\"], r=2):\n",
    "        idi, idj = ti[\"id\"], tj[\"id\"]\n",
    "        mutualmatrix.loc[idi, idj] = mutualmatrix.loc[idi, idj] + 1\n",
    "        mutualmatrix.loc[idj, idi] = mutualmatrix.loc[idj, idi] + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-zero elements in mutual matrix: 18001\n",
      "Total sum of values in mutual matrix: 63228\n"
     ]
    }
   ],
   "source": [
    "# Count non-zero elements and total sum in the mutual matrix\n",
    "nonzero_count = (mutualmatrix != 0).sum().sum()\n",
    "total_sum = mutualmatrix.sum().sum()\n",
    "print(f\"Number of non-zero elements in mutual matrix: {nonzero_count}\")\n",
    "print(f\"Total sum of values in mutual matrix: {total_sum}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(mutualmatrix)\n",
    "probmatrix = mutualmatrix/N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "('https://openalex.org/T11468', 'https://openalex.org/T12561')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/Coding/refBro/env/lib/python3.13/site-packages/pandas/core/indexes/base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[0;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mpandas/_libs/hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: ('https://openalex.org/T11468', 'https://openalex.org/T12561')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m pmimatrix \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39minf, index\u001b[38;5;241m=\u001b[39mprobmatrix\u001b[38;5;241m.\u001b[39mindex, columns\u001b[38;5;241m=\u001b[39mprobmatrix\u001b[38;5;241m.\u001b[39mcolumns)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ti, tj \u001b[38;5;129;01min\u001b[39;00m combinations(pmimatrix\u001b[38;5;241m.\u001b[39mindex, r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     pmimatrix[ti, tj] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlog2(\u001b[43mprobmatrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43mti\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m/\u001b[39m(probmatrix[ti, ti]\u001b[38;5;241m*\u001b[39mprobmatrix[tj, tj]))\n",
      "File \u001b[0;32m~/Desktop/Coding/refBro/env/lib/python3.13/site-packages/pandas/core/frame.py:4102\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   4100\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mnlevels \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   4101\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_getitem_multilevel(key)\n\u001b[0;32m-> 4102\u001b[0m indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(indexer):\n\u001b[1;32m   4104\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m [indexer]\n",
      "File \u001b[0;32m~/Desktop/Coding/refBro/env/lib/python3.13/site-packages/pandas/core/indexes/base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[1;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[1;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[1;32m   3810\u001b[0m     ):\n\u001b[1;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[0;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[1;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[1;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[1;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[1;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[0;31mKeyError\u001b[0m: ('https://openalex.org/T11468', 'https://openalex.org/T12561')"
     ]
    }
   ],
   "source": [
    "pmimatrix = pd.DataFrame(-np.inf, index=probmatrix.index, columns=probmatrix.columns)\n",
    "for ti, tj in combinations(pmimatrix.index, r=2):\n",
    "    pmimatrix[ti, tj] = np.log2(probmatrix[ti, tj]/(probmatrix[ti, ti]*probmatrix[tj, tj]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
