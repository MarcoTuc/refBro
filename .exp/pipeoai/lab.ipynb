{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords_out = 10\n",
    "\n",
    "# role of an expert keyword searcher\n",
    "role_keyword_searcher = f\"\"\"You are a scientist, expert and master in constructing text queries for scholarly search engines. \n",
    "Your text queries are short and concise, not more than 5 words and most likely about 3 words.\n",
    "When you create your set of queries you aim for diversity and counterintuitive queries that can potentially unveil unknown but very valuable papers.\"\"\"\n",
    "\n",
    "role_summarizer = f\"\"\"You are an experienced scientist in the craft of writing review papers that summarize the commonalities and highlight the differences between a given list of papers.\"\"\"\n",
    "\n",
    "# formatting explanation for keywords list\n",
    "explain_list_format_kw = f\"\"\"You are going to format your list of keyword searches as a list of strings such as in the following example:\n",
    "[\"search_1\", \"search_2\", \"search_3\", \"search_4\", \"search_5\", \"search_6\", \"search_7\", \"search_8\", \"search_9\", \"search_10\"]\"\"\"\n",
    "\n",
    "# system prompt for going from a list of abstracts to a list of queries\n",
    "system_prompt_1 = f\"\"\"{role_keyword_searcher}\n",
    "You are given by the user a list of titles and abstracts and from such list you will produce a list of 10 keyword searches that will unveil interesting results that can greatly impact the research directions given by the user list of titles and abstracts. The list of titles and abstracts is served in the following format: \n",
    "title:: text of first title\n",
    "abstract: text of first abstract\n",
    "------\n",
    "title:: text of second title\n",
    "abstract: text of second abstract \n",
    "------\n",
    "and so on for all the results the user asks for. In any case you are going to produce {keywords_out} and only {keywords_out}.\n",
    "{explain_list_format_kw}\"\"\"\n",
    "\n",
    "# system prompt for going from a list of abstracts to a summarizing extended abstract\n",
    "system_prompt_2_a = f\"\"\"{role_summarizer}\n",
    "You are given by the user the task of summarizing from a list of titles and abstracts, an extended abstract for a review paper about user given list of abstracts.\"\"\"\n",
    "\n",
    "# system prompt for going from an extended abstract to a list of queries\n",
    "system_prompt_2_b = f\"\"\"{role_keyword_searcher}\n",
    "You are given by the user an extended abstract from which you have to extract a list of 10 keyword searches that will unveil interesting results that can greatly impact the research directions highlighted int he extended abstract.\n",
    "{explain_list_format_kw}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from pydantic import BaseModel\n",
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI(api_key=os.getenv(\"OPENAI_REFBRO_KEY\"))\n",
    "\n",
    "class SearchList(BaseModel):\n",
    "    queries: list[str]\n",
    "\n",
    "def keywords_from_abstracts(formatted_abstracts: str):\n",
    "    completion = client.beta.chat.completions.parse(\n",
    "    model=\"gpt-4o\",\n",
    "    messages=[\n",
    "        {\"role\": \"system\", \"content\": f\"{system_prompt_1}\"},\n",
    "        {\"role\": \"user\", \"content\": f\"{formatted_abstracts}\"},\n",
    "    ],\n",
    "    response_format=SearchList,\n",
    "    )\n",
    "    # answer = oai.chat.completion.create(\n",
    "    #     model=\"gpt-4o\",\n",
    "    #     store=True,\n",
    "    #     messages=[\n",
    "    #         {\n",
    "    #             \"role\": \"system\",\n",
    "    #             \"content\": f\"{system_prompt_1}\"\n",
    "    #         },\n",
    "    #         {\n",
    "    #             \"role\": \"user\",\n",
    "    #             \"content\": f\"{formatted_abstracts}\"\n",
    "    #         }\n",
    "    #     ],\n",
    "    #     response_format=SearchList\n",
    "    # )\n",
    "    return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "import asyncio\n",
    "\n",
    "BASE_OPENALEX = \"https://api.openalex.org\"\n",
    "\n",
    "# TODO: move to openalex.py\n",
    "async def fetch_papers_async(query: str, n_results=1000):\n",
    "    query = \"%20\".join(query.split(\" \"))\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        tasks = []\n",
    "        per_page = 200\n",
    "        pages = (n_results // per_page) + 1\n",
    "        for page in range(1, pages + 1):\n",
    "            url = f\"{BASE_OPENALEX}/works?search={query}&per-page={per_page}&page={page}\"\n",
    "            tasks.append(session.get(url))\n",
    "        responses = await asyncio.gather(*tasks)\n",
    "        results = []\n",
    "        for response in responses:\n",
    "            data = await response.json()\n",
    "            results.extend(data['results']) # TODO: check behavior of extend\n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# TODO: move to openalex.py\n",
    "async def multi_search(queries, n_results=400) -> pd.DataFrame:\n",
    "    \"\"\" Returns a dataframe with all retrieved papers for all queries \"\"\"\n",
    "    results = {}\n",
    "    for query in queries: \n",
    "        results[query] = await fetch_papers_async(query, n_results=n_results)\n",
    "    return pd.concat(list(results.values()), ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\"dynamical systems\", \"quantum entanglement\", \"many body theorems\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers_search = await multi_search(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "papers = papers_search[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_738924/2035715235.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  papers[\"abstract\"] = None\n"
     ]
    }
   ],
   "source": [
    "papers[\"abstract\"] = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reconstruct_abstract(index: dict) -> str:\n",
    "    if isinstance(index, type(None)): return \"MISSING_ABSTRACT\" # TODO: expand with scraping methods TODO: decide if to return None instead\n",
    "    max_position_sum = sum([len(position)+1 for position in index.values()]) + 500 # + 500 for safety \n",
    "    abstract_array = max_position_sum*[None]\n",
    "    for word, positions in index.items():\n",
    "        for position in positions:\n",
    "            abstract_array[position] = word\n",
    "    abstract_array = [i for i in abstract_array if i is not None]\n",
    "    abstract_string = ' '.join(abstract_array)\n",
    "    abstract_string = abstract_string.replace(r'^abstract\\s+', '')\n",
    "    return abstract_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['id', 'doi', 'title', 'display_name', 'relevance_score',\n",
      "       'publication_year', 'publication_date', 'ids', 'language',\n",
      "       'primary_location', 'type', 'type_crossref', 'indexed_in',\n",
      "       'open_access', 'authorships', 'institution_assertions',\n",
      "       'countries_distinct_count', 'institutions_distinct_count',\n",
      "       'corresponding_author_ids', 'corresponding_institution_ids', 'apc_list',\n",
      "       'apc_paid', 'fwci', 'has_fulltext', 'fulltext_origin', 'cited_by_count',\n",
      "       'citation_normalized_percentile', 'cited_by_percentile_year', 'biblio',\n",
      "       'is_retracted', 'is_paratext', 'primary_topic', 'topics', 'keywords',\n",
      "       'concepts', 'mesh', 'locations_count', 'locations', 'best_oa_location',\n",
      "       'sustainable_development_goals', 'grants', 'datasets', 'versions',\n",
      "       'referenced_works_count', 'referenced_works', 'related_works',\n",
      "       'abstract_inverted_index', 'cited_by_api_url', 'counts_by_year',\n",
      "       'updated_date', 'created_date', 'abstract'],\n",
      "      dtype='object')\n",
      "{'is_oa': False, 'landing_page_url': 'https://doi.org/10.1109/72.80202', 'pdf_url': None, 'source': {'id': 'https://openalex.org/S42080949', 'display_name': 'IEEE Transactions on Neural Networks', 'issn_l': '1045-9227', 'issn': ['1045-9227', '1941-0093'], 'is_oa': False, 'is_in_doaj': False, 'is_core': True, 'host_organization': 'https://openalex.org/P4310319808', 'host_organization_name': 'Institute of Electrical and Electronics Engineers', 'host_organization_lineage': ['https://openalex.org/P4310319808'], 'host_organization_lineage_names': ['Institute of Electrical and Electronics Engineers'], 'type': 'journal'}, 'license': None, 'license_id': None, 'version': None, 'is_accepted': False, 'is_published': False}\n"
     ]
    }
   ],
   "source": [
    "print(papers.columns)\n",
    "print(papers[\"primary_location\"].iloc[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_738924/4169661470.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  papers[\"abstract\"] = papers[\"abstract_inverted_index\"].apply(reconstruct_abstract)\n"
     ]
    }
   ],
   "source": [
    "papers[\"abstract\"] = papers[\"abstract_inverted_index\"].apply(reconstruct_abstract)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56\n"
     ]
    }
   ],
   "source": [
    "papers = papers[papers[\"abstract\"] != \"MISSING_ABSTRACT\"]\n",
    "print(len(papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_prompt = \"\\n------\\n\".join(\n",
    "    f\"title:: {pap['title']}\\nabstract:: {pap['abstract']}\"\n",
    "    for _, pap in papers.iterrows()\n",
    ") + \"\\n------\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc = tiktoken.encoding_for_model(\"gpt-4o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9236"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(enc.encode(user_prompt))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = keywords_from_abstracts(user_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['neural network dynamics',\n",
       " 'situation awareness modeling',\n",
       " 'hyperbolic invariants',\n",
       " 'chaotic neuron simulations',\n",
       " 'digital feedback control',\n",
       " 'random perturbations analysis',\n",
       " 'flocking stability equations',\n",
       " 'turbulence coherent structures',\n",
       " 'nonlinear system approximation',\n",
       " 'sparse system identification']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries.choices[0].message.parsed.queries"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
