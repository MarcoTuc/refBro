{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/marco/Desktop/Coding/refBro/env/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "from main import embed_papers\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import chromadb\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SentenceTransformer(\"sentence-transformers/allenai-specter\")\n",
    "chroma_client = chromadb.PersistentClient(path=\"cool_data/recommender_systems\")\n",
    "collection = chroma_client.get_collection(\"recommender_systems\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.get_sentence_embedding_dimension()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "library = json.load(open(\"data/library.json\"))\n",
    "embedded_library = embed_papers(model, library)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_library_max_pool = np.max(np.array(embedded_library), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# placeholder for querying the vectordb\n",
    "results = collection.query(\n",
    "    query_embeddings=embedded_library_max_pool,\n",
    "    n_results=21\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[{'abstract': \"A bottom-up approach that enables readers to master and apply the latest techniques in state estimationThis book offers the best mathematical approaches to estimating the state of a general system. The author presents state estimation theory clearly and rigorously, providing the right amount of advanced material, recent research results, and references to enable the reader to apply state estimation techniques confidently across a variety of fields in science and engineering.While there are other textbooks that treat state estimation, this one offers special features and a unique perspective and pedagogical approach that speed learning:\\r\\n\\r\\n Straightforward, bottom-up approach begins with basic concepts and then builds step by step to more advanced topics for a clear understanding of state estimation\\r\\n Simple examples and problems that require only paper and pen to solve lead to an intuitive understanding of how theory works in practice\\r\\n MATLAB(r)-based source code that corresponds to examples in the book, available on the author's Web site, enables readers to recreate results and experiment with other simulation setups and parameters\\r\\n\\r\\nArmed with a solid foundation in the basics, readers are presented with a careful treatment of advanced topics, including unscented filtering, high order nonlinear filtering, particle filtering, constrained state estimation, reduced order filtering, robust Kalman filtering, and mixed Kalman/H? filtering.Problems at the end of each chapter include both written exercises and computer exercises. Written exercises focus on improving the reader's understanding of theory and key concepts, whereas computer exercises help readers apply theory to problems similar to ones they are likely to encounter in industry. A solutions manual is available for instructors.With its expert blend of theory and practice, coupled with its presentation of recent research results, Optimal State Estimation is strongly recommended for undergraduate and graduate-level courses in optimal control and state estimation theory. It also serves as a reference for engineers and science professionals across a wide array of industries.A solutions manual is available upon request from the Wiley editorial board.\",\n",
       "   'title': 'Optimal state estimation: Kalman, H [infinity], and nonlinear approaches'},\n",
       "  {'abstract': 'The Kalman Filter (KF) is one of the most widely used methods for tracking and estimation due to its simplicity, optimality, tractability and robustness. However, the application of the KF to nonlinear systems can be difficult. The most common approach is to use the Extended Kalman Filter (EKF) which simply linearizes all nonlinear models so that the traditional linear Kalman filter can be applied. Although the EKF (in its many forms) is a widely used filtering strategy, over thirty years of experience with it has led to a general consensus within the tracking and control community that it is difficult to implement, difficult to tune, and only reliable for systems which are almost linear on the time scale of the update intervals. In this paper a new linear estimator is developed and demonstrated. Using the principle that a set of discretely sampled points can be used to parameterize mean and covariance, the estimator yields performance equivalent to the KF for linear systems yet generalizes elegantly to nonlinear systems without the linearization steps required by the EKF. We show analytically that the expected performance of the new approach is superior to that of the EKF and, in fact, is directly comparable to that of the second order Gauss filter. The method is not restricted to assuming that the distributions of noise sources are Gaussian. We argue that the ease of implementation and more accurate estimation features of the new filter recommend its use over the EKF in virtually all applications.',\n",
       "   'title': 'New extension of the Kalman filter to nonlinear systems'},\n",
       "  {'abstract': 'Providing a unique approach to machine learning, this text contains fresh and intuitive, yet rigorous, descriptions of all fundamental concepts necessary to conduct research, build products, tinker, and play. By prioritizing geometric intuition, algorithmic thinking, and practical real world applications in disciplines including computer vision, natural language processing, economics, neuroscience, recommender systems, physics, and biology, this text provides readers with both a lucid understanding of foundational material as well as the practical tools needed to solve real-world problems. With in-depth Python and MATLAB/OCTAVE-based computational exercises and a complete treatment of cutting edge numerical optimization techniques, this is an essential resource for students and an ideal reference for researchers and practitioners working in machine learning, computer science, electrical engineering, signal processing, and numerical optimization.',\n",
       "   'title': 'Machine Learning Refined'},\n",
       "  {'abstract': \"9R2. Beyond Perturbation: Introduction to the Homotopy Analysis Method. - Edited by Shijun Liao (Shanghai Jiao Tong University, Shanghai, China). Chapman and Hall/CRC Press, Boca Raton FL. 2004. 322 pp. ISBN 1-58488-407-X.Reviewed by SA Sherif (Dept of Mech and Aerospace Eng, Univ of Florida, 232 MAE Bldg B, PO Box 116300, Gainesville FL 32611-6300).This book deals with a very interesting mathematical technique that is rather powerful. While perturbation methods work nicely for slightly nonlinear problems, the homotopy analysis technique addresses nonlinear problems in a more general manner. Through this method, the author demonstrates that a nonlinear problem that normally has a unique solution can have an infinite number of different solution expressions whose convergence region and rate are dependent on an auxiliary parameter. The method provides for ways to control and adjust the convergence region. This makes the method particularly suited for problems with strong nonlinearity. The book is comprised of two parts. Part I contains Chapters 1 through 5, while Part II contains Chapters 6 through 18. The first part covers the basic ideas and concepts of the method, while the second part focuses on applications of the method to different situations. In addition to introducing the method in Part I, the author discusses the relation of the method to other analytical methods as well as the advantages and limitations of the method. Applications discussed in Part II are varied in scope covering areas such as simple bifurcation of nonlinear problems, nonlinear eigenvalue problems, the Thomas-Fermi atom model, free oscillation systems with both odd and quadratic nonlinearities, Blasius' viscous flow, boundary layer flows with exponential and algebraic properties, von Karman's swirling viscous flow, and nonlinear progressive waves in deep water. The book should serve as an excellent reference to researchers, engineers, and interested individuals in helping them tackle nonlinear problems in an analytical fashion. It has a good subject index and an outstanding list of bibliography with 136 references cited. The book is very well written and is relatively easy to follow to the mathematically literate person. I highly recommend that it be acquired by interested individuals and libraries throughout.\",\n",
       "   'title': 'Beyond Perturbation: Introduction to the Homotopy Analysis Method'},\n",
       "  {'abstract': 'We start with a brief introduction to reinforcement learning (RL), about its successful stories, basics, an example, issues, the ICML 2019 Workshop on RL for Real Life, how to use it, study material and an outlook. Then we discuss a selection of RL applications, including recommender systems, computer systems, energy, finance, healthcare, robotics, and transportation.',\n",
       "   'title': 'Reinforcement Learning Applications'},\n",
       "  {'abstract': 'Cognitive task analysis is defined as the extension of traditional task analysis techniques to yield information about the knowledge, thought processes and goal structures that underlie observable task performance. Cognitive task analyses are conducted for a wide variety of purposes, including the design of computer systems to support human work, the development of training, and the development of tests to certify competence. As part of its Programme of Work, NATO Research Study Group 27 on Cognitive Task Analysis has undertaken the task of reviewing existing cognitive task analysis techniques. The Group concludes that few integrated methods exist, that little attention is being paid to the conditions under which methods are appropriate, and that often it is unclear how the products of cognitive task analysis should be used. RSG.27 has also organized a workshop with experts in the field of cognitive task analysis. The most important issues that were discussed during the workshop were: (1) the use of CTA in the design of new systems, (2) the question when to use what technique, and (3) the role of CTA in system design. RSG.27 emphasizes: (1) that is important for the CTA community to be able to empirically demonstrate the added value of a CTA; (2) it is critical for the success of CTA to be involved in the design process from the start to finish, and to establish clear links with methods that are used by other disciplines, and (3) recommends that more research effort be directed to the issue of the reliability of CTA techniques. (P)',\n",
       "   'title': 'Cognitive Task Analysis'},\n",
       "  {'abstract': 'Praise for the First Edition\\r\\n\\r\\n\\t. . . fills a considerable gap in the numerical analysis literature by providing a self-contained treatment . . . this is an important work written in a clear style . . . warmly recommended to any graduate student or researcher in the field of the numerical solution of partial differential equations.\\r\\n\\t—SIAM Review\\r\\n\\r\\n\\tTime-Dependent Problems and Difference Methods, Second Edition continues to provide guidance for the analysis of difference methods for computing approximate solutions to partial differential equations for time-dependent problems. The book treats differential equations and difference methods with a parallel development, thus achieving a more useful analysis of numerical methods.\\r\\n\\r\\n\\tThe Second Edition presents hyperbolic equations in great detail as well as new coverage on second-order systems of wave equations including acoustic waves, elastic waves, and Einstein equations. Compared to first-order hyperbolic systems, initial-boundary value problems for such systems contain new properties that must be taken into account when analyzing stability. Featuring the latest material in partial differential equations with new theorems, examples, and illustrations,Time-Dependent Problems and Difference Methods, Second Edition also includes:\\r\\n\\r\\n\\t\\r\\n\\t\\tHigh order methods on staggered grids\\r\\n\\t\\r\\n\\t\\tExtended treatment of Summation By Parts operators and their application to second-order derivatives\\r\\n\\t\\r\\n\\t\\tSimplified presentation of certain parts and proofs\\r\\n\\r\\n\\r\\n\\tTime-Dependent Problems and Difference Methods, Second Edition is an ideal reference for physical scientists, engineers, numerical analysts, and mathematical modelers who use numerical experiments to test designs and to predict and investigate physical phenomena. The book is also excellent for graduate-level courses in applied mathematics and scientific computations.',\n",
       "   'title': 'Time‐Dependent Problems and Difference Methods'},\n",
       "  {'abstract': 'Reinforcement learning (RL) algorithms find applications in inventory control, recommender systems, vehicular traffic management, cloud computing, and robotics. The real-world complications arising in these domains makes them difficult to solve with the basic assumptions underlying classical RL algorithms. RL agents in these applications often need to react and adapt to changing operating conditions. A significant part of research on single-agent RL techniques focuses on developing algorithms when the underlying assumption of stationary environment model is relaxed. This article provides a survey of RL methods developed for handling dynamically varying environment models. The goal of methods not limited by the stationarity assumption is to help autonomous agents adapt to varying operating conditions. This is possible either by minimizing the rewards lost during learning by RL agent or by finding a suitable policy for the RL agent that leads to efficient operation of the underlying system. A representative collection of these algorithms is discussed in detail in this work along with their categorization and their relative merits and demerits. Additionally, we also review works that are tailored to application domains. Finally, we discuss future enhancements for this field.',\n",
       "   'title': 'A Survey of Reinforcement Learning Algorithms for Dynamically Varying Environments'},\n",
       "  {'abstract': 'Diffusion coefficients of binary mixtures of dilute gases are comprehensively compiled, critically evaluated, and correlated by new semi-empirical expressions. There are seventy-four systems for which the data are sufficiently extensive, consistent and accurate to allow diffusion coefficients to be recommended with confidence. Deviation plots are given for most of these systems. Almost every gaseous diffusion coefficient which was experimentally determined and reported prior to 1970 can be obtained from the annotated bibliography and table of gas pairs. A detailed analysis of experimental methods is given, and intercomparison of their results helps establish reliability limits for the data, which depend strongly on temperature. Direct measurements are supplemented by calculations based on knowledge of intermolecular forces derived from independent sources—molecular beam scattering for high temperatures, and London dispersion constants for low temperatures. In addition, diffusion coefficients for several mixtures are obtained from experimental data on mixture viscosities and thermal diffusion factors. Combination of all these results gives diffusion coefficients over a very extensive temperature range, from very low temperatures to 10 000 K. All data are corrected for composition dependence and for quantum effects. New semi-empirical equations are derived for making such corrections easily.',\n",
       "   'title': 'Gaseous Diffusion Coefficients'},\n",
       "  {'abstract': \"I. SINGLE-DEGREE-OF-FREEDOM SYSTEMS. 1. Equations of Motion, Problem Statement, and Solution Methods. Simple Structures. Single-Degree-of-Freedom System. Force-Displacement Relation. Damping Force. Equation of Motion: External Force. Mass-Spring-Damper System. Equation of Motion: Earthquake Excitation. Problem Statement and Element Forces. Combining Static and Dynamic Responses. Methods of Solution of the Differential Equation. Study of SDF Systems: Organization. Appendix 1: Stiffness Coefficients for a Flexural Element. 2. Free Vibration. Undamped Free Vibration. Viscously Damped Free Vibration. Energy in Free Vibration. Coulomb-Damped Free Vibration. 3. Response to Harmonic and Periodic Excitations. Viscously Damped Systems: Basic Results. Harmonic Vibration of Undamped Systems. Harmonic Vibration with Viscous Damping. Viscously Damped Systems: Applications. Response to Vibration Generator. Natural Frequency and Damping from Harmonic Tests. Force Transmission and Vibration Isolation. Response to Ground Motion and Vibration Isolation. Vibration-Measuring Instruments. Energy Dissipated in Viscous Damping. Equivalent Viscous Damping. Systems with Nonviscous Damping. Harmonic Vibration with Rate-Independent Damping. Harmonic Vibration with Coulomb Friction. Response to Periodic Excitation. Fourier Series Representation. Response to Periodic Force. Appendix 3: Four-Way Logarithmic Graph Paper. 4. Response to Arbitrary, Step, and Pulse Excitations.Response to Arbitrarily Time-Varying Forces. Response to Unit Impulse. Response to Arbitrary Force. Response to Step and Ramp Forces. Step Force. Ramp or Linearly Increasing Force. Step Force with Finite Rise Time. Response to Pulse Excitations. Solution Methods. Rectangular Pulse Force. Half-Cycle Sine Pulse Force. Symmetrical Triangular Pulse Force. Effects of Pulse Shape and Approximate Analysis for Short Pulses. Effects of Viscous Damping. Response to Ground Motion. 5. Numerical Evaluation of Dynamic Response. Time-Stepping Methods. Methods Based on Interpolation of Excitation. Central Difference Method. Newmark's Method. Stability and Computational Error. Analysis of Nonlinear Response: Central Difference Method. Analysis of Nonlinear Response: Newmark's Method. 6. Earthquake Response of Linear Systems. Earthquake Excitation. Equation of Motion. Response Quantities. Response History. Response Spectrum Concept. Deformation, Pseudo-Velocity, and Pseudo-Acceleration Response Spectra. Peak Structural Response from the Response Spectrum. Response Spectrum Characteristics. Elastic Design Spectrum. Comparison of Design ad Response Spectra. Distinction between Design and Response Spectra. Velocity and Acceleration Response Spectra. Appendix 6: El Centro, 1940 Ground Motion. 7. Earthquake Response of Inelastic Systems. Force-Deformation Relations. Normalized Yield Strength, Yield Strength Reduction Factor, and Ductility Factor. Equation of Motion and Controlling Parameters. Effects of Yielding. Response Spectrum for Yield Deformation and Yield Strength. Yield Strength and Deformation from the Response Spectrum. Yield Strength-Ductility Relation. Relative Effects of Yielding and Damping. Dissipated Energy. Energy Dissipation Devices. Inelastic Design Spectrum. Applications of the Design Spectrum. Comparison of Design and Response Spectra. 8. Generalized Single-Degree-of-Freedom Systems. Generalized SDF Systems. Rigid-Body Assemblages. Systems with Distributed Mass and Elasticity. Lumped-Mass System: Shear Building. Natural Vibration Frequency by Rayleigh's Method. Selection of Shape Function. Appendix 8: Inertia Forces for Rigid Bodies. II. MULTI-DEGREE-OF-FREEDOM SYSTEMS. 9. Equations of Motion, Problem Statement, and Solution Methods. Simple System: Two-Story Shear Building. General Approach for Linear Systems. Static Condensation. Planar or Symmetric-Plan Systems: Ground Motion. Unsymmetric-Plan Building: Ground Motion. Symmetric-Plan Buildings: Torsional Excitation. Multiple Support Excitation. Inelastic Systems. Problem Statement. Element Forces. Methods for Solving the Equations of Motion: Overview. 10. Free Vibration. Natural Vibration Frequencies and Modes. Systems without Damping. Natural Vibration Frequencies and Modes. Modal and Spectral Matrices. Orthogonality of Modes. Interpretation of Modal Orthogonality. Normalization of Modes. Modal Expansion of Displacements. Free Vibration Response. Solution of Free Vibration Equations: Undamped Systems. Free Vibration of Systems with Damping. Solution of Free Vibration Equations: Classically Damped Systems. Computation of Vibration Properties. Solution Methods for the Eigenvalue Problem. Rayleigh's Quotient. Inverse Vector Iteration Method. Vector Iteration with Shifts: Preferred Procedure. Transformation of kA A = ...w2mA A to the Standard Form. 11. Damping in Structures.Experimental Data and Recommended Modal Damping Ratios. Vibration Properties of Millikan Library Building. Estimating Modal Damping Ratios. Construction of Damping Matrix. Damping Matrix. Classical Damping Matrix. Nonclassical Damping Matrix. 12. Dynamic Analysis and Response of Linear Systems.Two-Degree-of-Freedom Systems. Analysis of Two-DOF Systems without Damping. Vibration Absorber or Tuned Mass Damper. Modal Analysis. Modal Equations for Undamped Systems. Modal Equations for Damped Systems. Displacement Response. Element Forces. Modal Analysis: Summary. Modal Response Contributions. Modal Expansion of Excitation Vector p (t) = s p(T). Modal Analysis for p (t) = s p(T). Modal Contribution Factors. Modal Responses and Required Number of Modes. Special Analysis Procedures. Static Correction Method. Mode Acceleration Superposition Method. Analysis of Nonclassically Damped Systems. 13. Earthquake Analysis of Linear Systems.Response History Analysis. Modal Analysis. Multistory Buildings with Symmetric Plan. Multistory Buildings with Unsymmetric Plan. Torsional Response of Symmetric-Plan Buildings. Response Analysis for Multiple Support Excitation. Structural Idealization and Earthquake Response. Response Spectrum Analysis. Peak Response from Earthquake Response Spectrum. Multistory Buildings with Symmetric Plan. Multistory Buildings with Unsymmetric Plan. 14. Reduction of Degrees of Freedom. Kinematic Constraints. Mass Lumping in Selected DOFs. Rayleigh-Ritz Method. Selection of Ritz Vectors. Dynamic Analysis Using Ritz Vectors. 15. Numerical Evaluation of Dynamic Response. Time-Stepping Methods. Analysis of Linear Systems with Nonclassical Damping. Analysis of Nonlinear Systems. 16. Systems with Distributed Mass and Elasticity. Equation of Undamped Motion: Applied Forces. Equation of Undamped Motion: Support Excitation. Natural Vibration Frequencies and Modes. Modal Orthogonality. Modal Analysis of Forced Dynamic Response. Earthquake Response History Analysis. Earthquake Response Spectrum Analysis. Difficulty in Analyzing Practical Systems. 17. Introduction to the Finite Element Method.Rayleigh-Ritz Method. Formulation Using Conservation of Energy. Formulation Using Virtual Work. Disadvantages of Rayleigh-Ritz Method. Finite Element Method. Finite Element Approximation. Analysis Procedure. Element Degrees of Freedom and Interpolation Function. Element Stiffness Matrix. Element Mass Matrix. Element (Applied) Force Vector. Comparison of Finite Element and Exact Solutions. Dynamic Analysis of Structural Continua. III. EARTHQUAKE RESPONSE AND DESIGN OF MULTISTORY BUILDINGS. 18. Earthquake Response of Linearly Elastic Buildings. Systems Analyzed, Design Spectrum, and Response Quantities. Influence of T 1 and r on Response. Modal Contribution Factors. Influence of T 1 on Higher-Mode Response. Influence of r on Higher-Mode Response. Heightwise Variation of Higher-Mode Response. How Many Modes to Include. 19. Earthquake Response of Inelastic Buildings. Allowable Ductility and Ductility Demand. Buildings with Weak or Soft First Story. Buildings Designed for Code Force Distribution. Limited Scope. Appendix 19: Properties of Multistory Buildings. 20. Earthquake Dynamics of Base-Isolated Buildings. Isolation Systems. Base-Isolated One-Story Buildings. Effectiveness of Base Isolation. Base-Isolated Multistory Buildings. Applications of Base Isolation. 21. Structural Dynamics in Building Codes. Building Codes and Structural Dynamics. International Building Code (United States), 2000. National Building Code of Canada, 1995. Mexico Federal District Code, 1993. Eurocode 8. Structural Dynamics in Building Codes. Evaluation of Building Codes. Base Shear. Story Shears and Equivalent Static Forces. Overturning Moments. Concluding Remarks. Appendix A: Frequency Domain Method of Response Analysis.Appendix B: Notation.Appendix C: Answers to Selected Problems.Index.\",\n",
       "   'title': 'Dynamics of structures: theory and applications to earthquake engineering'},\n",
       "  {'abstract': 'This accessible and classroom-tested textbook/reference presents an introduction to the fundamentals of the emerging and interdisciplinary field of data science. The coverage spans key concepts adopted from statistics and machine learning, useful techniques for graph analysis and parallel programming, and the practical application of data science for such tasks as building recommender systems or performing sentiment analysis. Topics and features: provides numerous practical case studies using real-world data throughout the book; supports understanding through hands-on experience of solving data science problems using Python; describes techniques and tools for statistical analysis, machine learning, graph analysis, and parallel programming; reviews a range of applications of data science, including recommender systems and sentiment analysis of text data; provides supplementary code resources and data at an associated website.',\n",
       "   'title': 'Introduction to Data Science: A Python Approach to Concepts, Techniques and Applications'},\n",
       "  {'abstract': 'We describe a framework for analyzing simulation output in order to find solutions that will work well after implementation. We show how the use of a loss function that incorporates both system mean and system variability can be used to efficiently and effectively carry out system optimization and improvement efforts. For models whose behavior depends on quantitative factors, we illustrate how robust design can be accomplished by using simple experimental designs in conjunction with response-surface metamodels. The results can yield new insights into system behavior, and may lead to recommended system configurations that differ substantially from those selected by analysis solely on the basis of mean response.',\n",
       "   'title': 'Robust design: seeking the best of all possible worlds'},\n",
       "  {'abstract': \"The relationship between co-integration and error correction models, first suggested in Granger (1981), is here extended and used to develop estimation procedures, tests, and empirical examples. If each element of a vector of time series x first achieves stationarity after differencing, but a linear combination a'x is already stationary, the time series x are said to be co-integrated with co-integrating vector a. There may be several such co-integrating vectors so that a becomes a matrix. Interpreting a'x,= 0 as a long run equilibrium, co-integration implies that deviations from equilibrium are stationary, with finite variance, even though the series themselves are nonstationary and have infinite variance. The paper presents a representation theorem based on Granger (1983), which connects the moving average, autoregressive, and error correction representations for co-integrated systems. A vector autoregression in differenced variables is incompatible with these representations. Estimation of these models is discussed and a simple but asymptotically efficient two-step estimator is proposed. Testing for co-integration combines the problems of unit root tests and tests with parameters unidentified under the null. Seven statistics are formulated and analyzed. The critical values of these statistics are calculated based on a Monte Carlo simulation. Using these critical values, the power properties of the tests are examined and one test procedure is recommended for application. In a series of examples it is found that consumption and income are co-integrated, wages and prices are not, short and long interest rates are, and nominal GNP is co-integrated with M2, but not M1, M3, or aggregate liquid assets.\",\n",
       "   'title': 'Co-Integration and Error Correction: Representation, Estimation, and Testing'},\n",
       "  {'abstract': 'In this article we survey ambient intelligence (AmI), including its applications, some of the technologies it uses, and its social and ethical implications. The applications include AmI at home, care of the elderly, healthcare, commerce, and business, recommender systems, museums and tourist scenarios, and group decision making. Among technologies, we focus on ambient data management and artificial intelligence; for example planning, learning, event-condition-action rules, temporal reasoning, and agent-oriented technologies. The survey is not intended to be exhaustive, but to convey a broad range of applications, technologies, and technical, social, and ethical challenges.',\n",
       "   'title': 'Ambient intelligence'},\n",
       "  {'abstract': 'Abstract Dispersion corrections to standard Kohn–Sham density functional theory (DFT) are reviewed. The focus is on computationally efficient methods for large systems that do not depend on virtual orbitals or rely on separated fragments. The recommended approaches (van der Waals density functional and DFT‐D) are asymptotically correct and can be used in combination with standard or slightly modified (short‐range) exchange–correlation functionals. The importance of the dispersion energy in intramolecular cases (conformational problems and thermochemistry) is highlighted. © 2011 John Wiley &amp; Sons, Ltd. WIREs Comput Mol Sci 2011 1 211‐228 DOI: 10.1002/wcms.30 This article is categorized under: Electronic Structure Theory &gt; Density Functional Theory',\n",
       "   'title': 'Density functional theory with London dispersion corrections'},\n",
       "  {'abstract': \"1R5. Nonholonomic Mechanics and Control. - AM Bloch (Dept of Math, Univ of Michigan, Ann Arbor MI 48109-1109). Springer-Verlag, New York. 2003. 483 pp. ISBN 0-387-95535-6. $69.95.Reviewed by B Brogliato (INRA, 655 Ave De L'Europe, Saint Ismier, 38334, France).This mathematically oriented book is dedicated to the modeling and control of a class of nonlinear mechanical systems, namely mechanical systems subject to nonholonomic (or non integrable) bilateral constraints. It is known that the control of such nonlinear systems requires specific tools, as they may not be stabilizable with continuous feedbacks, as a consequence of Brockett's necessary conditions. Such problems have received considerable attention in the applied mathematics, mechanics, and systems and control communities, for many years. Therefore, this is a topic of major importance. The audience will mainly consist of graduate students, researchers, either working in this field or with a sufficiently advanced mathematical background (especially differential geometry tools). The book starts with an introductory chapter with many examples treated in detail. The next two chapters are devoted to presenting the mathematical tools needed to study such systems. This material will certainly be hard to follow for those who have no acquaintance in differential geometry and its applications to mechanics. However, in view of the literature on the subject, understanding the basics from geometry seems to be mandatory for someone who wants to understand the control of such mechanical systems. The fourth chapter is dedicated to nonlinear control theory, still with an emphasis on geometry. Controllability, stability and stabilization are reviewed, and the chapter ends with Hamiltonian and Lagrangian control systems. The fifth and sixth chapters are devoted to nonholonomic systems, their dynamics and their control. Stabilization techniques are explained, like time-varying and nonsmooth controllers. Here one can regret that the bibliography omits C Samson, one of the first contributors to the field and who introduced time-varying controllers for the control of chained systems in the paper Velocity and torque feedback control of a nonholonomic cart, in Advanced Robot Control, Proceedings of the International Workshop on Nonlinear and Adaptive Control: Issues in Robotics, Grenoble, France, November 21-23, 1990, Springer Verlag LNCIS 162. Samson's paper Control of chained systems: Application to path following and time-varying point stabilization, IEEE Trans on Automatic Control, Volume 40, pp 64-77, 1995, would have also been welcome in the bibliography. Chapter 7 deals with optimal control and variational principles. The eighth chapter concerns stability analysis with energy arguments (generalization of the Lejeune-Dirichlet theorem on stability of fixed points). In a logical way the last chapter is devoted to energy-based control and stabilization. There are many other books that cover the topic of nonholonomic mechanical systems control in one or two chapters (for instance Sastry's book in the same Springer's series, or the book Theory of Robot Control, Springer CCE Series, 1996). But Nonholonomic Mechanics and Control is entirely dedicated to this topic and covers the aspects of modeling, analysis and control. It clearly belongs to the realm of geometry-oriented works in mechanics or control. The book is well organized, contains many examples and exercises, and can be recommended to all researchers working in the field (applied mathematics, mechanics or control).\",\n",
       "   'title': 'Nonholonomic Mechanics and Control'},\n",
       "  {'abstract': 'We outline a model for types and levels of automation that provides a framework and an objective basis for deciding which system functions should be automated and to what extent. Appropriate selection is important because automation does not merely supplant but changes human activity and can impose new coordination demands on the human operator. We propose that automation can be applied to four broad classes of functions: 1) information acquisition; 2) information analysis; 3) decision and action selection; and 4) action implementation. Within each of these types, automation can be applied across a continuum of levels from low to high, i.e., from fully manual to fully automatic. A particular system can involve automation of all four types at different levels. The human performance consequences of particular types and levels of automation constitute primary evaluative criteria for automation design using our model. Secondary evaluative criteria include automation reliability and the costs of decision/action consequences, among others. Examples of recommended types and levels of automation are provided to illustrate the application of the model to automation design.',\n",
       "   'title': 'A model for types and levels of human interaction with automation'},\n",
       "  {'abstract': \"ABSTRACT Mechanical Turk (MTurk), an online labor system run by Amazon.com, provides quick, easy, and inexpensive access to online research participants. As use of MTurk has grown, so have questions from behavioral researchers about its participants, reliability, and low compensation. In this article, we review recent research about MTurk and compare MTurk participants with community and student samples on a set of personality dimensions and classic decision‐making biases. Across two studies, we find many similarities between MTurk participants and traditional samples, but we also find important differences. For instance, MTurk participants are less likely to pay attention to experimental materials, reducing statistical power. They are more likely to use the Internet to find answers, even with no incentive for correct responses. MTurk participants have attitudes about money that are different from a community sample's attitudes but similar to students' attitudes. Finally, MTurk participants are less extraverted and have lower self‐esteem than other participants, presenting challenges for some research domains. Despite these differences, MTurk participants produce reliable results consistent with standard decision‐making biases: they are present biased, risk‐averse for gains, risk‐seeking for losses, show delay/expedite asymmetries, and show the certainty effect—with almost no significant differences in effect sizes from other samples. We conclude that MTurk offers a highly valuable opportunity for data collection and recommend that researchers using MTurk (1) include screening questions that gauge attention and language comprehension; (2) avoid questions with factual answers; and (3) consider how individual differences in financial and social domains may influence results. Copyright © 2012 John Wiley &amp; Sons, Ltd.\",\n",
       "   'title': 'Data Collection in a Flat World: The Strengths and Weaknesses of Mechanical Turk Samples'},\n",
       "  {'abstract': 'This document updates the first version of the IUPAC technical report on “Chemical actinometers” published in Pure Appl. Chem . 61 ,187-210 (1989). Since then, some methods have been improved, procedures have been modified, and new substances have been proposed as chemical actinometers. An actinometer is a chemical system or a physical device by which the number of photons in a beam absorbed into the defined space of a chemical reactor can be determined integrally or per time. This compilation includes chemical actinometers for the gas, solid, microheterogeneous, and liquid phases, as well as for the use with pulsed lasers for the measurement of transient absorbances, including the quantum yield of phototransformation, as well as the literature for each of the actinometers. The actinometers listed are for the use in the wavelength range from the UV to the red region of the spectrum. A set of recommended standard procedures is also given. Advantages and disadvantages are discussed regarding the use of chemical actinometers vs. electronic devices for the measurement of the number of photons absorbed. Procedures for the absolute measurement of incident photon flux by means of photodiodes are also discussed.',\n",
       "   'title': 'Chemical actinometry (IUPAC Technical Report)'},\n",
       "  {'abstract': 'This compilation updates and expands two previous evaluations of kinetic data on elementary, homogeneous, gas phase reactions of neutral species involved in combustion systems [J. Phys. Chem. Ref Data 21, 411 (1992); 23, 847 (1994)]. The work has been carried out under the auspices of the IUPAC Commission on Chemical Kinetics and the UK Engineering and Physical Sciences Research Council. Individual data sheets are presented for most reactions but the kinetic data for reactions of C2, C, ethyl, i-propyl, t-butyl, and allyl radicals are summarized in tables. Each data sheet sets out relevant thermodynamic data, experimental kinetic data, references, recommended rate parameters with their error limits and a brief discussion of the reasons for their selection. Where appropriate the data are displayed on an Arrhenius diagram or by fall-off curves. Tables summarizing the recommended rate data and the thermodynamic data for the reactant and product species are given, and their sources referenced. As in the previous evaluations the reactions considered relate largely to the combustion in air of organic compounds containing up to three carbon atoms and simple aromatic compounds. Thus the data base has been expanded, largely by dealing with a substantial number of extra reactions within these general areas.',\n",
       "   'title': 'Evaluated Kinetic Data for Combustion Modeling: Supplement II'},\n",
       "  {'abstract': 'In this paper we develop and investigate the properrties of a novel system, called the residue code or residue number system. The residue number system is of particular interest because the arithmetic operations of addition and multiplication may be executed in the same time as required for an addition operation. The main difficulty of the residue code relative to arithmetic operations is the determination of the relative magnitude of two numbers expressed in the residue code. The residue code is probably of little utility for general-purpose computation, but the code has many characteristics which recommend its use for special-purpose computations.',\n",
       "   'title': 'The residue number system'}]]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[\"metadatas\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
